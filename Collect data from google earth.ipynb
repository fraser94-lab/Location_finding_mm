{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "To crop an image based on a blue bounding box, you'll need to perform the following steps:\n",
    "\n",
    "Load the image using a library like PIL or OpenCV.\n",
    "Convert the image to an array of pixel values.\n",
    "Use a color detection algorithm to identify the blue bounding box. One simple approach would be to check each pixel in the image to see if its blue value is above a certain threshold.\n",
    "Use the bounding box coordinates to crop the image.\n",
    "Save the cropped image.\n",
    "Here's some example code that demonstrates how to crop an image based on a blue bounding box using OpenCV:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('input_image.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply a Gaussian blur to the grayscale image to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply a threshold to create a binary image of the blue regions\n",
    "thresh = cv2.threshold(blurred, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the largest blue contour (the bounding box)\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Get the bounding box coordinates\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "# Crop the image based on the bounding box coordinates\n",
    "cropped = img[y:y+h, x:x+w]\n",
    "\n",
    "# Save the cropped image\n",
    "cv2.imwrite('output_image.png', cropped)\n",
    "Note that this is just one example approach, and the specific color detection and contour finding algorithms used here may need to be adjusted for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4517ac7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m core_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/vboxuser/Documents/location_mm_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m data_input_file\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(core_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m files\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mpath_file\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(files)\n\u001b[1;32m     13\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_file' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "core_path=\"/home/vboxuser/Documents/location_mm_data/\"\n",
    "\n",
    "data_input_file=os.path.join(core_path,\"original images\")\n",
    "\n",
    "files=os.listdir(path_file)\n",
    "\n",
    "print(files)\n",
    "\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b97ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2747697929.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 41\u001b[0;36m\u001b[0m\n\u001b[0;31m    Note that this is just one example approach, and the specific color detection and contour finding algorithms used here may need to be adjusted for your specific use case.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "core_path=\"/home/vboxuser/Documents/location_mm_data/\"\n",
    "\n",
    "data_input_file=os.path.join(core_path,\"original images\")\n",
    "\n",
    "files=os.listdir(path_file)\n",
    "\n",
    "print(files)\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('input_image.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply a Gaussian blur to the grayscale image to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply a threshold to create a binary image of the blue regions\n",
    "thresh = cv2.threshold(blurred, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Find the largest blue contour (the bounding box)\n",
    "largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "# Get the bounding box coordinates\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "# Crop the image based on the bounding box coordinates\n",
    "cropped = img[y:y+h, x:x+w]\n",
    "\n",
    "# Save the cropped image\n",
    "cv2.imwrite('output_image.png', cropped)\n",
    "Note that this is just one example approach, and the specific color detection and contour finding algorithms used here may need to be adjusted for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24a1b11",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (3787148260.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Yes, you can use Python to convert a PNG image into a GeoTIFF file with the correct geographic metadata, given that you know the coordinates of the four corners of the image. Here's an example workflow to achieve this using the rasterio library:\u001b[0m\n\u001b[0m                                                                                                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "Yes, you can use Python to convert a PNG image into a GeoTIFF file with the correct geographic metadata, given that you know the coordinates of the four corners of the image. Here's an example workflow to achieve this using the rasterio library:\n",
    "\n",
    "Load the PNG image into a NumPy array using the imageio library:\n",
    "python\n",
    "Copy code\n",
    "import imageio\n",
    "\n",
    "img = imageio.imread('input_image.png')\n",
    "Determine the size of the image in pixels:\n",
    "python\n",
    "Copy code\n",
    "height, width = img.shape[:2]\n",
    "Create a new rasterio dataset with the desired metadata, including the size of the image, the geospatial coordinates of the four corners, and the desired projection information:\n",
    "python\n",
    "Copy code\n",
    "import rasterio\n",
    "\n",
    "# Set the geospatial coordinates of the four corners\n",
    "top_left = (lon1, lat1)\n",
    "top_right = (lon2, lat2)\n",
    "bottom_left = (lon3, lat3)\n",
    "bottom_right = (lon4, lat4)\n",
    "\n",
    "# Set the desired projection information\n",
    "crs = rasterio.crs.CRS.from_epsg(4326) # WGS 84\n",
    "\n",
    "# Create the metadata dictionary\n",
    "meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'count': 3, # Number of bands (RGB)\n",
    "    'crs': crs,\n",
    "    'transform': rasterio.transform.from_bounds(*bottom_left, *top_right, width, height)\n",
    "}\n",
    "\n",
    "# Create a new rasterio dataset with the metadata\n",
    "with rasterio.open('output_image.tif', 'w', **meta) as dst:\n",
    "    dst.write(img, indexes=[1, 2, 3])\n",
    "This will create a new GeoTIFF file with the same pixel values as the input PNG image, but with the correct geographic metadata based on the four corner coordinates provided. Note that you may need to adjust the metadata and projection information to match the specific requirements of your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea74382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
